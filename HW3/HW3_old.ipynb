{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OCx8JUqUKKNX"
   },
   "source": [
    "1. Написать Dataset для задачи seq2seq\n",
    "2. Реализовать модель\n",
    "3. Сделать цикл обучения\n",
    "4. Реализовать метод генерации ответа по вопросу с помощью вашей модели\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_rya88ToKZy0"
   },
   "source": [
    "1. Сделать модель, основанную на lstm/gru 5 баллов ✓\n",
    "2. Сделать модель, основанную на cnn 7 баллов\n",
    "3. Сделать модель, основанную на трансформере (реализовать все слои самому) 10 баллов\n",
    "4. Добавить в rnn/cnn модель attention 5 баллов ✓\n",
    "5. Реализовать жадное семплирование (генерацию по самому вероятному токену, как выше в языковой модели) 3 балла ✓\n",
    "6. Реализовать beam search 5 баллов\n",
    "7. Реализовать nucleus sampling 5 баллов ✓\n",
    "8. Добавить condition в модель 3 балла\n",
    "9. Добавить layer norm/residual в cnn или rnn модель 1 балл ✓\n",
    "10. Реализовать аккамуляцию градиентов 1 балл\n",
    "11. Сделать телеграм бота 2 балла\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "uwss-7-j-0IH"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-5-eca44f8771b7>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtorch\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mnn\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mstring\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mpunctuation\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mwhitespace\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 11\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0msrc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mutils\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mtrain_bpe\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     12\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import youtokentome as yttm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from typing import Iterable, List, Tuple\n",
    "import torch\n",
    "from torch import nn\n",
    "from string import punctuation, whitespace\n",
    "from src.utils import train_bpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "zncculvv-0IP"
   },
   "outputs": [],
   "source": [
    "ZIP_PATH = 'qa_data.jsonl.zip'\n",
    "FILE_NAME = 'qa_data.jsonl'\n",
    "BPE_TEXT_PATH = 'bpe_raw.txt'\n",
    "BPE_MODEL_PATH = 'bpe_qa.model'\n",
    "VOCAB_SIZE = 7000\n",
    "MAX_SOURCE_LEN = 32\n",
    "MAX_TARGET_LEN = 32\n",
    "QA_MODEL_PATH = 'qa_model.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_data = list()\n",
    "with open(ZIP_PATH) as ZipFile\n",
    "with open('qa_data.jsonl') as file_object:\n",
    "    for line in file_object:\n",
    "        qa_data.append(json.loads(line.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "bPZEjx8h-0Ig"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'qa_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-9-127a618fb53c>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m     \u001B[0mtrain_bpe\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mqa_data\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbpe_text_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbpe_model_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m7000\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m: name 'qa_data' is not defined"
     ]
    }
   ],
   "source": [
    "if 1:\n",
    "    train_bpe(qa_data, bpe_text_path, bpe_model_path, 7000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "UDTCPAY4-0Im"
   },
   "outputs": [],
   "source": [
    "bpe = yttm.BPE(model=bpe_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DtudzEb2-0Iq",
    "outputId": "1e0eb32f-cb05-40b8-b795-c37dc6032dfb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<PAD>', '<UNK>', '<BOS>', '<EOS>', '▁']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe.vocab()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "VlfZOnrR-0Iu"
   },
   "outputs": [],
   "source": [
    "class SeqToSeqDataset(Dataset):\n",
    "\n",
    "    def __init__(self,\n",
    "                 qa_data: Iterable[dict],\n",
    "                 tokenizer,\n",
    "                 max_length: int = 128,\n",
    "                 pad_index: int = 0,\n",
    "                 unk_index: int = 1,\n",
    "                 bos_index: int = 2,\n",
    "                 eos_index: int = 3,\n",
    "                 pre_pad: bool = False):\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        self.qa_data = self.remove_empty_answers(qa_data)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.pad_index = pad_index\n",
    "        self.unk_index = unk_index\n",
    "        self.bos_index = bos_index\n",
    "        self.eos_index = eos_index\n",
    "        self.pre_pad = pre_pad\n",
    "\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.qa_data)\n",
    "\n",
    "    def filter_unk(self, token_indices: List[int]) -> List[int]:\n",
    "        output = []\n",
    "        unk_flag = False\n",
    "        for token in token_indices:\n",
    "            if token != self.unk_index:\n",
    "                output.append(token)\n",
    "            elif token == self.unk_index and not unk_flag:\n",
    "                unk_flag = True\n",
    "                output.append(token)\n",
    "            else:\n",
    "                pass\n",
    "        return output\n",
    "\n",
    "    def tokenize(self,\n",
    "                 text: str,\n",
    "                 bos: bool = True,\n",
    "                 eos: bool = True) -> List[int]:\n",
    "\n",
    "        tokens = self.tokenizer.encode(text,\n",
    "                                       eos=eos,\n",
    "                                       bos=bos)\n",
    "        \n",
    "\n",
    "        return tokens\n",
    "\n",
    "    def padding(self, tokenized_text: List[int]) -> List[int]:\n",
    "\n",
    "        # tokenized_text = self.filter_unk(tokenized_text)\n",
    "        if tokenized_text[-1] == self.eos_index:\n",
    "            tokenized_text = tokenized_text[:self.max_length]\n",
    "            tokenized_text[-1] = self.eos_index\n",
    "        else:\n",
    "            tokenized_text = tokenized_text[:self.max_length]\n",
    "        \n",
    "\n",
    "        if self.pre_pad:\n",
    "            tokenized_text = [self.pad_index] * (self.max_length - len(tokenized_text)) + tokenized_text\n",
    "        else:\n",
    "            tokenized_text += [self.pad_index] * (self.max_length - len(tokenized_text))\n",
    "\n",
    "        return tokenized_text\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[List[int], List[int], List[int]]:\n",
    "        \n",
    "        qa = self.qa_data[index]\n",
    "        \n",
    "        question = self.clean_text(qa['question'])\n",
    "        answers = qa['responses']\n",
    "        \n",
    "        answer_index = np.random.randint(0, len(answers))\n",
    "        answer = answers[answer_index]\n",
    "        \n",
    "        encoder_sequence = torch.Tensor(self.padding(self.tokenize(question,\n",
    "                                                                   bos=True,\n",
    "                                                                   eos=True))).long()\n",
    "        decoder_sequence = torch.Tensor(self.padding(self.tokenize(answer,\n",
    "                                                                   bos=True,\n",
    "                                                                   eos=False))).long()\n",
    "        target_sequence = torch.Tensor(self.padding(self.tokenize(answer,\n",
    "                                                                  bos=False,\n",
    "                                                                  eos=True))).long()\n",
    "        \n",
    "        return encoder_sequence, decoder_sequence, target_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "5zA3sbWWFExT"
   },
   "outputs": [],
   "source": [
    "class SpatialDropout(torch.nn.Dropout2d):\n",
    "    \n",
    "    def __init__(self, p=0.5):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(2)    # (N, T, 1, K)\n",
    "        x = x.permute(0, 3, 2, 1)  # (N, K, 1, T)\n",
    "        x = super(SpatialDropout, self).forward(x)  # (N, K, 1, T)\n",
    "        x = x.permute(0, 3, 2, 1)  # (N, T, 1, K)\n",
    "        x = x.squeeze(2)  # (N, T, K)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "-fPWONAU-0Ix"
   },
   "outputs": [],
   "source": [
    "class AttentionLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 dim: int):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.dim = dim\n",
    "        \n",
    "        self.key_projection = nn.Linear(in_features=self.dim,\n",
    "                                        out_features=self.dim)\n",
    "        self.value_projection = nn.Linear(in_features=self.dim,\n",
    "                                          out_features=self.dim)\n",
    "        self.query_projection = nn.Linear(in_features=self.dim,\n",
    "                                          out_features=self.dim)\n",
    "        \n",
    "        self.scale_factor = np.sqrt(self.dim)\n",
    "\n",
    "    @staticmethod\n",
    "    def mask_pads(weights, x_len, max_len):\n",
    "        mask = torch.arange(max_len)[None, :] < x_len[:, None]\n",
    "        masked_weights = weights.clone()\n",
    "        masked_weights[~mask] = float('-inf')\n",
    "        return masked_weights\n",
    "        \n",
    "    def forward(self, x, y, x_len, max_len):\n",
    "        \n",
    "        query = self.query_projection(y) # (batch_size, seq_len, dim)\n",
    "        key = self.key_projection(x) # (batch_size, seq_len, dim)\n",
    "        value = self.value_projection(x) # (batch_size, seq_len, dim)\n",
    "        \n",
    "        attention_weights = torch.bmm(query, key.permute(0, 2, 1)) # (batch_size, seq_len, seq_len)\n",
    "        attention_weights /= self.scale_factor\n",
    "        \n",
    "        attention_weights = self.mask_pads(attention_weights,\n",
    "                                           x_len=x_ len,\n",
    "                                           max_len=max_len) \n",
    "               \n",
    "        attention_weights = torch.softmax(attention_weights, dim=1) # (batch_size, seq_len, seq_len)\n",
    "\n",
    "\n",
    "        \n",
    "        attention = torch.bmm(attention_weights, value) # (batch_size, seq_len, dim)\n",
    "        \n",
    "        return y + attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "1S_DOgt5-0Iz"
   },
   "outputs": [],
   "source": [
    "class MyNet(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 dim: int,\n",
    "                 hidden_size: int,\n",
    "                 vocab_size: int,\n",
    "                 dropout: float,\n",
    "                 max_len: int = 64,\n",
    "                 pad_index: int = 0,\n",
    "                 weight_tying=True):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.dim = dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.max_len = max_len\n",
    "        self.vocab_size = vocab_size\n",
    "        self.pad_index = pad_index\n",
    "        self.weight_tying = weight_tying\n",
    "        \n",
    "        self.embedding_layer = nn.Embedding(num_embeddings=self.vocab_size,\n",
    "                                            embedding_dim=self.dim,\n",
    "                                            padding_idx=self.pad_index)\n",
    "        \n",
    "        self.embedding_dropout = SpatialDropout(p=dropout)\n",
    "        \n",
    "        self.attention_layer = AttentionLayer(self.dim)\n",
    "        \n",
    "        self.lstm_1 = nn.LSTM(self.dim,\n",
    "                              self.hidden_size,\n",
    "                              batch_first=True,\n",
    "                              bidirectional=False)\n",
    "        \n",
    "        self.lstm_2 = nn.LSTM(self.dim,\n",
    "                              self.hidden_size,\n",
    "                              batch_first=True,\n",
    "                              bidirectional=False)  \n",
    "        \n",
    "        self.final_output = nn.Linear(in_features=self.hidden_size,\n",
    "                                      out_features=self.vocab_size)\n",
    "        \n",
    "        if self.weight_tying and self.dim == self.hidden_size:\n",
    "            self.final_output.weight = self.embedding_layer.weight\n",
    "            \n",
    "    @staticmethod\n",
    "    def count_pads(x, axis=1):\n",
    "        try:\n",
    "          x = x.cpu()\n",
    "        except:\n",
    "          x = x\n",
    "        return torch.Tensor(np.count_nonzero(x, axis=axis))\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "\n",
    "        x_lengths = self.count_pads(x)\n",
    "        y_lengths = self.count_pads(y)\n",
    "\n",
    "\n",
    "        x = self.embedding_layer(x)\n",
    "        x = self.embedding_dropout(x)\n",
    "        y = self.embedding_layer(y)\n",
    "        y = self.embedding_dropout(y)\n",
    "\n",
    "\n",
    "\n",
    "        x = pack_padded_sequence(x,\n",
    "                                 x_lengths,\n",
    "                                 batch_first=True,\n",
    "                                 enforce_sorted=False)\n",
    "        \n",
    "        \n",
    "        y = pack_padded_sequence(y,\n",
    "                                 y_lengths,\n",
    "                                 batch_first=True,\n",
    "                                 enforce_sorted=False)\n",
    "        \n",
    "        x, memory = self.lstm_1(x)\n",
    "        y, _ = self.lstm_2(y, memory)\n",
    "        \n",
    "\n",
    "        x = pad_packed_sequence(x,\n",
    "                                batch_first=True,\n",
    "                                total_length=self.max_len)[0]\n",
    "        y = pad_packed_sequence(y,\n",
    "                                batch_first=True,\n",
    "                                total_length=self.max_len)[0]\n",
    "\n",
    "      \n",
    "\n",
    "        y = self.attention_layer(x,\n",
    "                                 y,\n",
    "                                 x_len=x_lengths,\n",
    "                                 max_len=self.max_len)\n",
    "        \n",
    "        y = self.final_output(y)\n",
    "        \n",
    "        return y # softmax?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "nsjZUSPE-0I1"
   },
   "outputs": [],
   "source": [
    "def train(model,\n",
    "          loader,\n",
    "          criterion,\n",
    "          optimizer,\n",
    "          gpu: bool = True,\n",
    "          clip:float = 3.,\n",
    "          last_n_losses: int = 500,\n",
    "          verbose: bool = True):\n",
    "  \n",
    "    losses = []\n",
    "\n",
    "    progress_bar = tqdm(total=len(loader), disable=not verbose, desc='Train')\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for encoder_sequence, decoder_sequence, target_sequence in loader:\n",
    "        \n",
    "        if gpu:\n",
    "            encoder_sequence = encoder_sequence.to(device)\n",
    "            decoder_sequence = decoder_sequence.to(device)\n",
    "            target_sequence = target_sequence.to(device)\n",
    "\n",
    "        pred = model(encoder_sequence, decoder_sequence)\n",
    "\n",
    "        loss = criterion(pred.view(-1, pred.size(-1)), target_sequence.view(-1))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        progress_bar.set_postfix(loss=np.mean(losses[-last_n_losses:]),\n",
    "                                 perplexity=np.exp(np.mean(losses[-last_n_losses:])))\n",
    "\n",
    "        progress_bar.update()\n",
    "\n",
    "    progress_bar.close()\n",
    "    \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "11NsR0HpH5tb"
   },
   "outputs": [],
   "source": [
    "def evaluate(model,\n",
    "             loader,\n",
    "             criterion,\n",
    "             gpu: bool = True,\n",
    "             last_n_losses: int = 500,\n",
    "             verbose: bool = True):\n",
    "    \n",
    "    losses = []\n",
    "\n",
    "    progress_bar = tqdm(total=len(loader), disable=not verbose, desc='Evaluate')\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for encoder_sequence, decoder_sequence, target_sequence in loader:\n",
    "        \n",
    "        if gpu:\n",
    "            encoder_sequence = encoder_sequence.to(device)\n",
    "            decoder_sequence = decoder_sequence.to(device)\n",
    "            target_sequence = target_sequence.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = model(encoder_sequence, decoder_sequence)\n",
    "\n",
    "        loss = criterion(pred.view(-1, pred.size(-1)), target_sequence.view(-1))\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        progress_bar.set_postfix(loss=np.mean(losses[-last_n_losses:]),\n",
    "                                 perplexity=np.exp(np.mean(losses[-last_n_losses:])))\n",
    "\n",
    "        progress_bar.update()\n",
    "\n",
    "    progress_bar.close()\n",
    "    \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "SkftYXWiIbGN"
   },
   "outputs": [],
   "source": [
    "train_len = int(np.floor(len(qa_data) * 0.95))\n",
    "train_data = qa_data[:train_len]\n",
    "valid_data = qa_data[train_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "a_fsow5uBD8z"
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "n8zKZx3o-0I3"
   },
   "outputs": [],
   "source": [
    "train_ds = SeqToSeqDataset(train_data, bpe, max_length=MAX_LEN)\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=512)\n",
    "\n",
    "valid_ds = SeqToSeqDataset(valid_data, bpe, max_length=MAX_LEN)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_ds, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "ufykRG73-0I5"
   },
   "outputs": [],
   "source": [
    "model = MyNet(dim=256,\n",
    "              hidden_size=256,\n",
    "              vocab_size=bpe.vocab_size(),\n",
    "              dropout=0.2,\n",
    "              max_len=MAX_LEN,\n",
    "              weight_tying=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "UP4q3hTi-0I7"
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "iOJQu8vS-0I-"
   },
   "outputs": [],
   "source": [
    "for instance in list(tqdm._instances):\n",
    "    tqdm._decr_instances(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GdQ4OtN6CzTE",
    "outputId": "959dffcb-9f12-468d-fab6-cdbf91872fd4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5PUAO3tQDV3j",
    "outputId": "ef4a0005-70d9-4c84-b1c1-4f72fb1ba89f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyNet(\n",
       "  (embedding_layer): Embedding(5, 256, padding_idx=0)\n",
       "  (embedding_dropout): SpatialDropout(p=0.2, inplace=False)\n",
       "  (attention_layer): AttentionLayer(\n",
       "    (key_projection): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (value_projection): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (query_projection): Linear(in_features=256, out_features=256, bias=True)\n",
       "  )\n",
       "  (lstm_1): LSTM(256, 256, batch_first=True)\n",
       "  (lstm_2): LSTM(256, 256, batch_first=True)\n",
       "  (final_output): Linear(in_features=256, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(model, train_loader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "POz3kbA5Hy6R",
    "outputId": "d67e844b-89ac-407b-83f8-8a3573ff9ec9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 0it [00:00, ?it/s]\n",
      "Evaluate: 0it [00:00, ?it/s]\n",
      "Train: 0it [00:00, ?it/s]\n",
      "Evaluate: 0it [00:00, ?it/s]\n",
      "Train: 0it [00:00, ?it/s]\n",
      "Evaluate: 0it [00:00, ?it/s]\n",
      "Train: 0it [00:00, ?it/s]\n",
      "Evaluate: 0it [00:00, ?it/s]\n",
      "Train: 0it [00:00, ?it/s]\n",
      "Evaluate: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train: loss - nan | perplexity - nan\n",
      "Validation: loss - nan | perplexity - nan\n",
      "Epoch: 2\n",
      "Train: loss - nan | perplexity - nan\n",
      "Validation: loss - nan | perplexity - nan\n",
      "Epoch: 3\n",
      "Train: loss - nan | perplexity - nan\n",
      "Validation: loss - nan | perplexity - nan\n",
      "Epoch: 4\n",
      "Train: loss - nan | perplexity - nan\n",
      "Validation: loss - nan | perplexity - nan\n",
      "Epoch: 5\n",
      "Train: loss - nan | perplexity - nan\n",
      "Validation: loss - nan | perplexity - nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "train_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "train_perplexities = []\n",
    "validation_perplexities = []\n",
    "\n",
    "best_validation_loss = 1e+6\n",
    "\n",
    "for n_epoch in range(1, epochs + 1):\n",
    "    \n",
    "    epoch_train_losses = train(model, train_loader, criterion, optimizer)\n",
    "    epoch_validation_losses = evaluate(model, valid_loader, criterion)\n",
    "    \n",
    "    mean_train_loss = np.mean(epoch_train_losses)\n",
    "    mean_validation_loss = np.mean(epoch_validation_losses)\n",
    "    \n",
    "    train_losses.append(epoch_train_losses)\n",
    "    train_perplexities.append(np.exp(mean_train_loss))\n",
    "    \n",
    "    validation_losses.append(epoch_validation_losses)\n",
    "    validation_perplexities.append(np.exp(mean_validation_loss))\n",
    "    \n",
    "    message = f'Epoch: {n_epoch}\\n'\n",
    "    message += f'Train: loss - {mean_train_loss:.4f} | perplexity - {train_perplexities[-1]:.3f}\\n'\n",
    "    message += f'Validation: loss - {mean_validation_loss:.4f} | perplexity - {validation_perplexities[-1]:.3f}'\n",
    "    \n",
    "    print(message)\n",
    "    \n",
    "#     if mean_validation_loss < best_validation_loss:\n",
    "        \n",
    "#         best_validation_loss = mean_validation_loss\n",
    "        \n",
    "#         torch.save(model.state_dict(), f'best_language_model_state_dict.pth')\n",
    "#         torch.save(optimizer.state_dict(), 'best_optimizer_state_dict.pth')\n",
    "        \n",
    "#     else:\n",
    "#         break\n",
    "        \n",
    "    torch.save(model.state_dict(), f'last_language_model_state_dict.pth')\n",
    "    torch.save(optimizer.state_dict(), 'last_optimizer_state_dict.pth')\n",
    "\n",
    "    with open(f'info_{n_epoch}.json', 'w') as file_object:\n",
    "\n",
    "        info = {\n",
    "            'message': message,\n",
    "            'train_losses': train_losses,\n",
    "            'validation_losses': validation_losses,\n",
    "            'train_perplexities': train_perplexities,\n",
    "            'validation_perplexities': validation_perplexities\n",
    "        }\n",
    "\n",
    "        file_object.write(json.dumps(info, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_jT8GybYT3LN"
   },
   "source": [
    "### Greedy Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6kUnePtgIkhx"
   },
   "outputs": [],
   "source": [
    "def generate(question,\n",
    "             tokenizer,\n",
    "             bos_index=2,\n",
    "             eos_index=3,\n",
    "             max_sequence=32):\n",
    "  \n",
    "    if max_sequence > MAX_LEN:\n",
    "      raise ValueError\n",
    "\n",
    "    tokenized = tokenizer.encode(question, eos=True, bos=True)\n",
    "    # tokenized += [0] * (MAX_LEN - len(tokenized))\n",
    "    \n",
    "    encoder_sequence = torch.tensor([tokenized]).long().to(device)\n",
    "    decoder_sequence = torch.tensor([bos_index]).long().unsqueeze(0).to(device)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "      for timestamp in range(max_sequence):\n",
    "        predictions = model(encoder_sequence, decoder_sequence)\n",
    "        current_token = predictions[:, -1, :].argmax(dim=-1)\n",
    "        if current_token == eos_index:\n",
    "          break\n",
    "        decoder_sequence = torch.cat([decoder_sequence, current_token.unsqueeze(0)], dim=-1)\n",
    "    # return decoder_sequence\n",
    "\n",
    "    answer = tokenizer.decode(decoder_sequence.squeeze(0).tolist())\n",
    "    answer = answer[0].lstrip('<BOS>').rstrip('<EOS>')\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "3i49gHGG_FTF",
    "outputId": "65162325-1d67-41fd-e050-5aa74e4bbad1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'я из черного в шоколадный хочу покрасится,'"
      ]
     },
     "execution_count": 82,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data[160]['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2t0tqu8GIrZG"
   },
   "outputs": [],
   "source": [
    "generate(valid_data[160]['question'], bpe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FG7SnVu_IHbU"
   },
   "source": [
    "### Nucleus Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ACsMfR0zZkb5"
   },
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "def nucleus(question,\n",
    "            tokenizer,\n",
    "            p=0.92,\n",
    "            bos_index=2,\n",
    "            eos_index=3,\n",
    "            max_sequence=32):\n",
    "  \n",
    "    if max_sequence > MAX_LEN:\n",
    "      raise ValueError\n",
    "\n",
    "    tokenized = tokenizer.encode(question, eos=True, bos=True)\n",
    "    # tokenized += [0] * (MAX_LEN - len(tokenized))\n",
    "    \n",
    "    encoder_sequence = torch.tensor([tokenized]).long().to(device)\n",
    "    decoder_sequence = torch.tensor([bos_index]).long().unsqueeze(0).to(device)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "      for timestamp in range(max_sequence):\n",
    "        # по идее это и есть условная вероятность следущего слова:\n",
    "        predictions = torch.softmax(model(encoder_sequence, decoder_sequence), dim=-1)\n",
    "        candidate_probs, candidate_tokens = predictions[:, -1, :].sort(dim=-1, descending=True)\n",
    "        # ищем индекс, левее которого вероятности складываются в `p`\n",
    "        candidate_probs = torch.cumsum(candidate_probs, dim=-1)\n",
    "        # еще один softmax, чтобы выбранные вероятности снова складывались в единицу\n",
    "        candidate_probs = softmax(candidate_probs[candidate_probs < p].cpu().numpy())\n",
    "        candidate_tokens = candidate_tokens[:, :candidate_probs.shape[0]].squeeze(0).cpu().numpy()\n",
    "        current_token = np.random.choice(candidate_tokens, p=candidate_probs)\n",
    "        if current_token == eos_index:\n",
    "          break\n",
    "        current_token = torch.Tensor([current_token]).long().to(device)\n",
    "        decoder_sequence = torch.cat([decoder_sequence, current_token.unsqueeze(0)], dim=-1)\n",
    "    # return decoder_sequence\n",
    "\n",
    "    answer = tokenizer.decode(decoder_sequence.squeeze(0).tolist())\n",
    "    answer = answer[0].lstrip('<BOS>').rstrip('<EOS>')\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "iSTaq6VjmgdX",
    "outputId": "b7e333e0-bf7f-4dea-ecdf-eeb67b3a5e63"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "' поез приблизатьрылик онлайн мальчика постоя руга поли алекса настучески приходи чтобству зая отсут женщинам бюджетколо коричне егэлик скорость фамилия пить зем профи изуля отли'"
      ]
     },
     "execution_count": 79,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nucleus(valid_data[160]['question'], bpe, p=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q0ntzMU-m0jQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "HW3_GPU.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}