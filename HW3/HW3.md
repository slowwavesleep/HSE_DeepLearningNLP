## Что нужно было сделать
1. Написать Dataset для задачи seq2seq
2. Реализовать модель
3. Сделать цикл обучения
4. Реализовать метод генерации ответа по вопросу с помощью вашей модели

## Что было сделано (отмечено ✓)

1. Сделать модель, основанную на lstm/gru 5 баллов ✓
2. Сделать модель, основанную на cnn 7 баллов
3. Сделать модель, основанную на трансформере (реализовать все слои самому) 10 баллов
4. Добавить в rnn/cnn модель attention 5 баллов ✓
5. Реализовать жадное семплирование (генерацию по самому вероятному токену, как выше в языковой модели) 3 балла ✓
6. Реализовать beam search 5 баллов
7. Реализовать nucleus sampling 5 баллов ✓
8. Добавить condition в модель 3 балла
9. Добавить layer norm/residual в cnn или rnn модель 1 балл ✓
10. Реализовать аккамуляцию градиентов 1 балл
11. Сделать телеграм бота 2 балла
Конвертируем json в более удобный формат.

## Шаги решения

`1.` Сначала я преобразовал данные в более удобный формат: файлы `source` и
`target` содержат пары вопросов и ответов на них.
```
python convert_data.py
```
`2.` Затем данные были разделены на train, dev, test.
```
python split_data.py data/source data/target data 42
```
`3.` Обучил модель и нагенерировал ответы с помощью **greedy search**
и **nucleus sampling** (файлы `greedy_responses.txt` и `nucleus_responses.txt` в
папке `results`).
```
python train.py
```
